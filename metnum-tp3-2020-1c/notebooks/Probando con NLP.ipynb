{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/.pyenv/versions/3.6.5/envs/metnum-tp3/lib/python3.6/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import metnum\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "from Model import Model\n",
    "from Segment import Segment\n",
    "from NlpModel import NlpModel\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error as RMSE, mean_squared_log_error as RMSLE, balanced_accuracy_score as BAS, make_scorer\n",
    "from sklearn.preprocessing import scale, normalize\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 240000 entries, 0 to 239999\n",
      "Data columns (total 24 columns):\n",
      " #   Column                      Non-Null Count   Dtype  \n",
      "---  ------                      --------------   -----  \n",
      " 0   id                          240000 non-null  int64  \n",
      " 1   titulo                      234613 non-null  object \n",
      " 2   descripcion                 238381 non-null  object \n",
      " 3   tipodepropiedad             239954 non-null  object \n",
      " 4   direccion                   186928 non-null  object \n",
      " 5   ciudad                      239628 non-null  object \n",
      " 6   provincia                   239845 non-null  object \n",
      " 7   antiguedad                  196445 non-null  float64\n",
      " 8   habitaciones                217529 non-null  float64\n",
      " 9   garages                     202235 non-null  float64\n",
      " 10  banos                       213779 non-null  float64\n",
      " 11  metroscubiertos             222600 non-null  float64\n",
      " 12  metrostotales               188533 non-null  float64\n",
      " 13  idzona                      211379 non-null  float64\n",
      " 14  lat                         116512 non-null  float64\n",
      " 15  lng                         116512 non-null  float64\n",
      " 16  fecha                       240000 non-null  object \n",
      " 17  gimnasio                    240000 non-null  float64\n",
      " 18  usosmultiples               240000 non-null  float64\n",
      " 19  piscina                     240000 non-null  float64\n",
      " 20  escuelascercanas            240000 non-null  float64\n",
      " 21  centroscomercialescercanos  240000 non-null  float64\n",
      " 22  precio                      240000 non-null  float64\n",
      " 23  urbana                      240000 non-null  bool   \n",
      "dtypes: bool(1), float64(15), int64(1), object(7)\n",
      "memory usage: 42.3+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df_original = pd.read_csv('../data/train.csv')\n",
    "train_df = train_df_original.copy()\n",
    "\n",
    "train_df['urbana'] = (train_df['escuelascercanas'] > 0) & (train_df['centroscomercialescercanos'] > 0 )\n",
    "\n",
    "train_df.info()\n",
    "test_df_original = pd.read_csv('../data/test.csv')\n",
    "test_df = test_df_original.copy()\n",
    "# test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropeo las huertas porque solo hay una\n",
    "train_df = train_df.drop(train_df[train_df['tipodepropiedad'] == 'Huerta'].index)\n",
    "# Dropeo las quintas vacacionales porque solo los precios son cualquiera\n",
    "train_df = train_df.drop(train_df[train_df['tipodepropiedad'] == 'Quinta Vacacional'].index)\n",
    "# Dropeo los ranchos porque solo los precios son cualquiera\n",
    "train_df = train_df.drop(train_df[train_df['tipodepropiedad'] == 'Rancho'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_column = 'precio'\n",
    "carititud_column = \"carititud\"\n",
    "#segments = ['tipodepropiedad', 'usosmultiples', 'banos']\n",
    "segments = ['urbana', 'provincia']\n",
    "text_features = ['titulo', 'descripcion']\n",
    "features = ['metrostotales', 'metroscubiertos', 'garages']\n",
    "\n",
    "model1 = NlpModel(train_df, text_features=text_features, features=features, segment_columns=segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 3) Processing count, total=   6.3s\n",
      "[Pipeline] .............. (step 2 of 3) Processing desc, total=  11.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/.pyenv/versions/3.6.5/envs/metnum-tp3/lib/python3.6/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing reg, total=  31.4s\n"
     ]
    }
   ],
   "source": [
    "model1.fit_nlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error calculando metricas en segmento /False/Zacatecas:\n",
      "Mean Squared Logarithmic Error cannot be used when targets contain negative values.\n"
     ]
    }
   ],
   "source": [
    "model1.regresionar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.prom_scores()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.scores_por_segmento()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones = model1.predict_rows(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## De aca en adelante esta el calculo de los metaparametros para la red\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-aec19825ea53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "model1.segments.map(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sonCaras(precios):\n",
    "    mean = precios.mean()\n",
    "    min_val = precios.min()\n",
    "    max_val = precios.max()\n",
    "    return np.array([esCara(p, mean, max_val, min_val) for p in precios])\n",
    "    \n",
    "def esCara(precio, mean, max_val, min_val):\n",
    "    if precio > mean:\n",
    "        if precio > mean + (max_val - mean) / 2:\n",
    "            return 3\n",
    "        else:\n",
    "            return 2\n",
    "    else:\n",
    "        if precio > min_val + (mean - min_val) / 2:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "train_df[carititud_column] = sonCaras(df_train[predict_column].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buscando predecir el precio directamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=3, max_features=5000)\n",
    "vectorizer.fit(x_train) # Notar que no le muestro el test \n",
    "\n",
    "x_train_transf = scale(vectorizer.transform(x_train), with_mean=False)\n",
    "x_test_transf = scale(vectorizer.transform(x_test), with_mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(n_components=100)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saco componentes principales\n",
    "tsvd = TruncatedSVD(100)\n",
    "tsvd.fit(x_train_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_transf = tsvd.transform(x_train_transf)\n",
    "x_test_transf = tsvd.transform(x_test_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "741.9866979147752"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsvd.explained_variance_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.51546139\n",
      "Validation score: -0.039834\n",
      "Iteration 2, loss = 0.44509959\n",
      "Validation score: -0.008313\n",
      "Iteration 3, loss = 0.43801872\n",
      "Validation score: -0.005355\n",
      "Iteration 4, loss = 0.43694414\n",
      "Validation score: -0.003124\n",
      "Iteration 5, loss = 0.43620054\n",
      "Validation score: -0.002753\n",
      "Iteration 6, loss = 0.43584307\n",
      "Validation score: -0.002084\n",
      "Iteration 7, loss = 0.43568954\n",
      "Validation score: -0.002472\n",
      "Iteration 8, loss = 0.43561472\n",
      "Validation score: -0.002264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awolfsdorf/.pyenv/versions/3.7.5/envs/mettp3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:587: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(early_stopping=True, hidden_layer_sizes=(100, 200, 50),\n",
       "             learning_rate='adaptive', random_state=1, solver='sgd',\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = MLPRegressor(\n",
    "    solver='sgd', learning_rate='adaptive', early_stopping=True,\n",
    "    hidden_layer_sizes=(100,200,50), max_iter=200, random_state=1, verbose=True)\n",
    "regr.fit(x_train_transf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.435614723929101"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07693442191101652\n",
      "-0.022941062631672837\n"
     ]
    }
   ],
   "source": [
    "print(regr.score(x_train_transf, y_train))\n",
    "print(regr.score(x_test_transf, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.01E+00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.539</td>\n",
       "      <td>1.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.214</td>\n",
       "      <td>0.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.097</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.309</td>\n",
       "      <td>1.242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.214</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.283</td>\n",
       "      <td>1.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.701</td>\n",
       "      <td>1.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.840</td>\n",
       "      <td>1.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.376</td>\n",
       "      <td>0.987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      real  pred\n",
       "0    0.539 1.072\n",
       "1    0.214 0.951\n",
       "2    0.330 0.940\n",
       "3    0.097 0.945\n",
       "4    0.309 1.242\n",
       "...    ...   ...\n",
       "1995 0.214 0.892\n",
       "1996 0.283 1.070\n",
       "1997 0.701 1.013\n",
       "1998 0.840 1.083\n",
       "1999 0.376 0.987\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real = y_test\n",
    "predicted = regr.predict(x_test_transf)\n",
    "err = RMSE(predicted, real)\n",
    "print(\"{:.2E}\".format(err))\n",
    "to_show = pd.DataFrame()\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "to_show[\"real\"] = real\n",
    "to_show[\"pred\"] = predicted\n",
    "to_show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(x_train_transf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30765479486534103"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.score(x_train_transf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30691947899406424"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.score(x_test_transf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probando con Clasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# A parameter grid for the pipeline\n",
    "params = {\n",
    "    # Bag of Words\n",
    "    'count__min_df': [2, 5, 10],\n",
    "    'count__max_features': [200, 500, 1000, 5000],\n",
    "\n",
    "    # Descompositer\n",
    "    'desc__n_components': [100, 500, 1000],\n",
    "\n",
    "    # Classificator\n",
    "    'clf__min_child_weight': [1, 5, 10],\n",
    "    'clf__gamma': [0.5, 1, 1.5, 2, 5],\n",
    "    'clf__subsample': [0.6, 0.8, 1.0],\n",
    "    'clf__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'clf__max_depth': [3, 5, 7, 10],\n",
    "    'clf__learning_rate': [0.01, 0.02, 0.05]    \n",
    "}\n",
    "\n",
    "folds = 3\n",
    "param_comb = 1\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=1000, \n",
    "                    silent=True, nthread=6, tree_method='gpu_hist')\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('count', CountVectorizer()),\n",
    "    ('desc', TruncatedSVD()),\n",
    "    ('clf', xgb)\n",
    "])\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline, param_distributions=params, n_iter=param_comb, scoring=make_scorer(BAS), \n",
    "    n_jobs=-1, cv=skf.split(x_train,y_train), random_state=1001\n",
    ")\n",
    "\n",
    "\n",
    "## Resultado \n",
    "best_params = {\n",
    "    'clf__colsample_bytree': 0.6,\n",
    "    'clf__gamma': 2,\n",
    "    'clf__learning_rate': 0.05,\n",
    "    'clf__max_depth': 7,\n",
    "    'clf__min_child_weight': 10,\n",
    "    'clf__subsample': 1.0,\n",
    "    'count__max_features': 1000,\n",
    "    'count__min_df': 5,\n",
    "    'desc__n_components': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:31:35] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x7ff824009c50>,\n",
       "                   estimator=Pipeline(steps=[('count', CountVectorizer()),\n",
       "                                             ('tfid', TfidfTransformer()),\n",
       "                                             ('clf',\n",
       "                                              XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            gamma=None,\n",
       "                                                            gpu_id=None,\n",
       "                                                            importance_type='gain',\n",
       "                                                            interaction_constraints=None,\n",
       "                                                            lear...\n",
       "                                                            n_estimators=1000,\n",
       "                                                            n_jobs=None,\n",
       "                                                            nthread=6,\n",
       "                                                            num_parallel_tree=None,\n",
       "                                                            random_state=None,\n",
       "                                                            reg_alpha=None,\n",
       "                                                            reg_lambda=None,\n",
       "                                                            scale_pos_weight=None,\n",
       "                                                            silent=True,\n",
       "                                                            subsample=None,\n",
       "                                                            tree_method='gpu_hist',\n",
       "                                                            validate_parameters=None,\n",
       "                                                            verbosity=None))]),\n",
       "                   n_iter=1, n_jobs=2,\n",
       "                   param_distributions={'clf__min_child_weight': [1, 5, 10]},\n",
       "                   random_state=1001,\n",
       "                   scoring=make_scorer(balanced_accuracy_score))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(x_train[:100], y_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37900874635568516"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-f44a8c5ec901>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.92E+00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30578</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       real  pred\n",
       "30578     1     3"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real = y_test\n",
    "predicted = estimator.predict(x_test)\n",
    "err = RMSE(predicted, real)\n",
    "print(\"{:.2E}\".format(err))\n",
    "to_show = pd.DataFrame()\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "to_show[\"real\"] = real\n",
    "to_show[\"pred\"] = predicted\n",
    "to_show[to_show[\"pred\"]==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A parameter grid for the pipeline\n",
    "params = {\n",
    "    # Bag of Words\n",
    "    'count__min_df': [2, 5, 10],\n",
    "    'count__max_features': [200, 500, 1000, 5000],\n",
    "\n",
    "    # Descompositer\n",
    "    'desc__n_components': [100, 500, 1000],\n",
    "\n",
    "    # Classificator\n",
    "    'reg__solver': ['sgd', 'adam'],\n",
    "    'reg__max_iter': [50, 100],\n",
    "    'reg__hidden_layer_sizes': [(100,), (50,20), (50)]  \n",
    "}\n",
    "\n",
    "folds = 3\n",
    "param_comb = 1\n",
    "\n",
    "# Uso KFold porque son valores continuos\n",
    "kf = KFold(n_splits=folds, shuffle=True, random_state = 1001)\n",
    "\n",
    "pipeline_reg = Pipeline([\n",
    "    ('count', CountVectorizer()),\n",
    "    ('desc', TruncatedSVD()),\n",
    "    ('reg', MLPRegressor())\n",
    "])\n",
    "\n",
    "random_search_reg = RandomizedSearchCV(\n",
    "    pipeline_reg, param_distributions=params, n_iter=param_comb, scoring='neg_mean_squared_error', \n",
    "    n_jobs=-1, cv=kf.split(x_train, y_train_scaled), random_state=1001, verbose=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
