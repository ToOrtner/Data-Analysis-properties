{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metnum\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from pprint import pprint\n",
    "from Model import Model\n",
    "from Segment import Segment\n",
    "# from NlpModel import NlpModel\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error as RMSE, mean_squared_log_error as RMSLE, balanced_accuracy_score as BAS, make_scorer\n",
    "from sklearn.preprocessing import scale, normalize\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_original = pd.read_csv('../data/train.csv')\n",
    "train_df = train_df_original.copy()\n",
    "# train_df.info()\n",
    "test_df_original = pd.read_csv('../data/test.csv')\n",
    "test_df = test_df_original.copy()\n",
    "# test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from Model import Model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "class NlpModel(Model):\n",
    "    \n",
    "    _text_feat_column = 'text_feat_column'\n",
    "    _nlp_feat_column = 'nlp_feat_column'\n",
    "    \n",
    "    def __init__(self, df, text_features, features, segment_columns, kfold=5, predict_column='precio', drop_na=True):\n",
    "        super().__init__(df, features, segment_columns, kfold, predict_column, False, drop_na=False)\n",
    "        self.text_features = text_features\n",
    "        self.df[self._text_feat_column] = df[text_features].astype(str).agg(' '.join, axis=1)\n",
    "        if drop_na:\n",
    "            self.df = self.df.dropna()\n",
    "        \n",
    "    def regresionar(self):\n",
    "        # Creo la columna con los datos del estimador con NLP\n",
    "        self._create_nlp_column()\n",
    "        # Agrego esa columna como una feature mas para usar en la regresion lineal\n",
    "        self.features.append(self._nlp_feat_column)\n",
    "        super().regresionar()\n",
    "        \n",
    "    def _create_nlp_column(self):\n",
    "        self.estimator = self._get_estimator()\n",
    "        X, y = self._get_data_to_fit()\n",
    "        self.estimator.fit(X, y)\n",
    "        self.df[self._nlp_feat_column] = self.estimator.predict(X)\n",
    "        \n",
    "        \n",
    "    def _get_estimator(self):\n",
    "        params = {\n",
    "            'count__max_features': 5000,\n",
    "            'count__min_df': 5,\n",
    "            'desc__n_components': 100,\n",
    "            'reg__hidden_layer_sizes': (50, 20),\n",
    "            'reg__max_iter': 50,\n",
    "            'reg__solver': 'adam'\n",
    "        }\n",
    "        \n",
    "        pipeline = Pipeline([\n",
    "            ('count', CountVectorizer()),\n",
    "            ('desc', TruncatedSVD()),\n",
    "            ('reg', MLPRegressor())\n",
    "        ], verbose=True)\n",
    "        \n",
    "        pipeline.set_params(**params)\n",
    "        \n",
    "        return pipeline\n",
    "    \n",
    "    def _get_data_to_fit(self):\n",
    "        X = self.df[self._text_feat_column].values\n",
    "\n",
    "        # Escalado de datos a predecir\n",
    "        scaler = StandardScaler(with_mean=False)\n",
    "        to_predict = self.df[self.predict_column].values.reshape(1,-1)\n",
    "        y = scaler.fit_transform(to_predict).reshape((-1,))\n",
    "        \n",
    "        return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_column = 'precio'\n",
    "carititud_column = \"carititud\"\n",
    "segments = ['ciudad']\n",
    "text_features = ['titulo','descripcion']\n",
    "features = ['metrostotales']\n",
    "model1 = NlpModel(train_df, text_features=text_features, features=features, segment_columns=segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metrostotales</th>\n",
       "      <th>banos</th>\n",
       "      <th>precio</th>\n",
       "      <th>text_feat_column</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2273000.0</td>\n",
       "      <td>depto. tipo a-402 depto. interior de 80.15m2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>180.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3600000.0</td>\n",
       "      <td>condominio horizontal en venta &lt;p&gt;entre sonora...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>166.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1200000.0</td>\n",
       "      <td>casa en venta urbi 3 recamaras tonala descripc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>650000.0</td>\n",
       "      <td>casa sola en toluca zinacantepec con credito i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1150000.0</td>\n",
       "      <td>paseos del sol bonito departamento en excelent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239993</th>\n",
       "      <td>150.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1650000.0</td>\n",
       "      <td>bugambilias (ciudad) coto privado de tan solo ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239994</th>\n",
       "      <td>90.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1350000.0</td>\n",
       "      <td>hermosa casa en villa de los belenes &lt;p&gt;modern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239996</th>\n",
       "      <td>250.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1940000.0</td>\n",
       "      <td>casa en condominio a 10 min. del centro de tol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239997</th>\n",
       "      <td>138.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3400000.0</td>\n",
       "      <td>nicolas san juan departamento con excelente ub...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239998</th>\n",
       "      <td>137.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2890000.0</td>\n",
       "      <td>casa sola. javier rojo gomez. casa sola, divid...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167403 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        metrostotales  banos     precio  \\\n",
       "0                80.0    2.0  2273000.0   \n",
       "1               180.0    2.0  3600000.0   \n",
       "2               166.0    2.0  1200000.0   \n",
       "3                67.0    1.0   650000.0   \n",
       "4                95.0    1.0  1150000.0   \n",
       "...               ...    ...        ...   \n",
       "239993          150.0    3.0  1650000.0   \n",
       "239994           90.0    2.0  1350000.0   \n",
       "239996          250.0    3.0  1940000.0   \n",
       "239997          138.0    2.0  3400000.0   \n",
       "239998          137.0    4.0  2890000.0   \n",
       "\n",
       "                                         text_feat_column  \n",
       "0       depto. tipo a-402 depto. interior de 80.15m2, ...  \n",
       "1       condominio horizontal en venta <p>entre sonora...  \n",
       "2       casa en venta urbi 3 recamaras tonala descripc...  \n",
       "3       casa sola en toluca zinacantepec con credito i...  \n",
       "4       paseos del sol bonito departamento en excelent...  \n",
       "...                                                   ...  \n",
       "239993  bugambilias (ciudad) coto privado de tan solo ...  \n",
       "239994  hermosa casa en villa de los belenes <p>modern...  \n",
       "239996  casa en condominio a 10 min. del centro de tol...  \n",
       "239997  nicolas san juan departamento con excelente ub...  \n",
       "239998  casa sola. javier rojo gomez. casa sola, divid...  \n",
       "\n",
       "[167403 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 3) Processing count, total=  11.1s\n",
      "[Pipeline] .............. (step 2 of 3) Processing desc, total=  23.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awolfsdorf/.pyenv/versions/3.7.5/envs/mettp3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:585: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............... (step 3 of 3) Processing reg, total= 2.8min\n"
     ]
    }
   ],
   "source": [
    "model1.regresionar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2344029240329.119, 0.2888972868153765, 0.2859870570697326,\n",
       "       9977161.140802711], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.error_gral()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sonCaras(precios):\n",
    "    mean = precios.mean()\n",
    "    min_val = precios.min()\n",
    "    max_val = precios.max()\n",
    "    return np.array([esCara(p, mean, max_val, min_val) for p in precios])\n",
    "    \n",
    "def esCara(precio, mean, max_val, min_val):\n",
    "    if precio > mean:\n",
    "        if precio > mean + (max_val - mean) / 2:\n",
    "            return 3\n",
    "        else:\n",
    "            return 2\n",
    "    else:\n",
    "        if precio > min_val + (mean - min_val) / 2:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "train_df[carititud_column] = sonCaras(df_train[predict_column].values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_train[[\"descripcion\", predict_column, carititud_column]].dropna()\n",
    "# df_test = df_test[[\"descripcion\", predict_column, carititud_column]].dropna()\n",
    "\n",
    "# x_train = df_train[\"descripcion\"].values\n",
    "# x_test = df_test[\"descripcion\"].values\n",
    "# y_train = df_train[carititud_column].values\n",
    "# y_test = df_test[carititud_column].values\n",
    "\n",
    "# y_train_scaled = scale(y_train) + 1 # Scale va de -1 a 1, con +1 va de 0 a 2, evito valores neg \n",
    "# y_test_scaled = scale(y_test) + 1 # Scale va de -1 a 1, con +1 va de 0 a 2, evito valores neg "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_df[[\"descripcion\", predict_column, carititud_column]].dropna()\n",
    "\n",
    "X = df[\"descripcion\"].values\n",
    "# y = scale(df[carititud_column].values) + 1 # Scale va de -1 a 1, con +1 va de 0 a 2, evito valores neg \n",
    "y = df[carititud_column].values\n",
    "\n",
    "x_train, x_test = train_test_split(X, test_size=.2)\n",
    "y_train, y_test = train_test_split(y, test_size=.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buscando predecir el precio directamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(min_df=3, max_features=5000)\n",
    "vectorizer.fit(x_train) # Notar que no le muestro el test \n",
    "\n",
    "x_train_transf = scale(vectorizer.transform(x_train), with_mean=False)\n",
    "x_test_transf = scale(vectorizer.transform(x_test), with_mean=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TruncatedSVD(n_components=100)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saco componentes principales\n",
    "tsvd = TruncatedSVD(100)\n",
    "tsvd.fit(x_train_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_transf = tsvd.transform(x_train_transf)\n",
    "x_test_transf = tsvd.transform(x_test_transf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "741.9866979147752"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsvd.explained_variance_.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.51546139\n",
      "Validation score: -0.039834\n",
      "Iteration 2, loss = 0.44509959\n",
      "Validation score: -0.008313\n",
      "Iteration 3, loss = 0.43801872\n",
      "Validation score: -0.005355\n",
      "Iteration 4, loss = 0.43694414\n",
      "Validation score: -0.003124\n",
      "Iteration 5, loss = 0.43620054\n",
      "Validation score: -0.002753\n",
      "Iteration 6, loss = 0.43584307\n",
      "Validation score: -0.002084\n",
      "Iteration 7, loss = 0.43568954\n",
      "Validation score: -0.002472\n",
      "Iteration 8, loss = 0.43561472\n",
      "Validation score: -0.002264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/awolfsdorf/.pyenv/versions/3.7.5/envs/mettp3/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:587: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(early_stopping=True, hidden_layer_sizes=(100, 200, 50),\n",
       "             learning_rate='adaptive', random_state=1, solver='sgd',\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr = MLPRegressor(\n",
    "    solver='sgd', learning_rate='adaptive', early_stopping=True,\n",
    "    hidden_layer_sizes=(100,200,50), max_iter=200, random_state=1, verbose=True)\n",
    "regr.fit(x_train_transf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.435614723929101"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regr.loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07693442191101652\n",
      "-0.022941062631672837\n"
     ]
    }
   ],
   "source": [
    "print(regr.score(x_train_transf, y_train))\n",
    "print(regr.score(x_test_transf, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.01E+00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.539</td>\n",
       "      <td>1.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.214</td>\n",
       "      <td>0.951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.330</td>\n",
       "      <td>0.940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.097</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.309</td>\n",
       "      <td>1.242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.214</td>\n",
       "      <td>0.892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.283</td>\n",
       "      <td>1.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.701</td>\n",
       "      <td>1.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.840</td>\n",
       "      <td>1.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.376</td>\n",
       "      <td>0.987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      real  pred\n",
       "0    0.539 1.072\n",
       "1    0.214 0.951\n",
       "2    0.330 0.940\n",
       "3    0.097 0.945\n",
       "4    0.309 1.242\n",
       "...    ...   ...\n",
       "1995 0.214 0.892\n",
       "1996 0.283 1.070\n",
       "1997 0.701 1.013\n",
       "1998 0.840 1.083\n",
       "1999 0.376 0.987\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real = y_test\n",
    "predicted = regr.predict(x_test_transf)\n",
    "err = RMSE(predicted, real)\n",
    "print(\"{:.2E}\".format(err))\n",
    "to_show = pd.DataFrame()\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "to_show[\"real\"] = real\n",
    "to_show[\"pred\"] = predicted\n",
    "to_show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier()"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd = SGDClassifier()\n",
    "sgd.fit(x_train_transf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30765479486534103"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.score(x_train_transf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30691947899406424"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd.score(x_test_transf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probando con Clasificadores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# A parameter grid for the pipeline\n",
    "params = {\n",
    "    # Bag of Words\n",
    "    'count__min_df': [2, 5, 10],\n",
    "    'count__max_features': [200, 500, 1000, 5000],\n",
    "\n",
    "    # Descompositer\n",
    "    'desc__n_components': [100, 500, 1000],\n",
    "\n",
    "    # Classificator\n",
    "    'clf__min_child_weight': [1, 5, 10],\n",
    "    'clf__gamma': [0.5, 1, 1.5, 2, 5],\n",
    "    'clf__subsample': [0.6, 0.8, 1.0],\n",
    "    'clf__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'clf__max_depth': [3, 5, 7, 10],\n",
    "    'clf__learning_rate': [0.01, 0.02, 0.05]    \n",
    "}\n",
    "\n",
    "folds = 3\n",
    "param_comb = 1\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=1000, \n",
    "                    silent=True, nthread=6, tree_method='gpu_hist')\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('count', CountVectorizer()),\n",
    "    ('desc', TruncatedSVD()),\n",
    "    ('clf', xgb)\n",
    "])\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    pipeline, param_distributions=params, n_iter=param_comb, scoring=make_scorer(BAS), \n",
    "    n_jobs=-1, cv=skf.split(x_train,y_train), random_state=1001\n",
    ")\n",
    "\n",
    "\n",
    "## Resultado \n",
    "best_params = {\n",
    "    'clf__colsample_bytree': 0.6,\n",
    "    'clf__gamma': 2,\n",
    "    'clf__learning_rate': 0.05,\n",
    "    'clf__max_depth': 7,\n",
    "    'clf__min_child_weight': 10,\n",
    "    'clf__subsample': 1.0,\n",
    "    'count__max_features': 1000,\n",
    "    'count__min_df': 5,\n",
    "    'desc__n_components': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:31:35] WARNING: /workspace/src/learner.cc:480: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=<generator object _BaseKFold.split at 0x7ff824009c50>,\n",
       "                   estimator=Pipeline(steps=[('count', CountVectorizer()),\n",
       "                                             ('tfid', TfidfTransformer()),\n",
       "                                             ('clf',\n",
       "                                              XGBClassifier(base_score=None,\n",
       "                                                            booster=None,\n",
       "                                                            colsample_bylevel=None,\n",
       "                                                            colsample_bynode=None,\n",
       "                                                            colsample_bytree=None,\n",
       "                                                            gamma=None,\n",
       "                                                            gpu_id=None,\n",
       "                                                            importance_type='gain',\n",
       "                                                            interaction_constraints=None,\n",
       "                                                            lear...\n",
       "                                                            n_estimators=1000,\n",
       "                                                            n_jobs=None,\n",
       "                                                            nthread=6,\n",
       "                                                            num_parallel_tree=None,\n",
       "                                                            random_state=None,\n",
       "                                                            reg_alpha=None,\n",
       "                                                            reg_lambda=None,\n",
       "                                                            scale_pos_weight=None,\n",
       "                                                            silent=True,\n",
       "                                                            subsample=None,\n",
       "                                                            tree_method='gpu_hist',\n",
       "                                                            validate_parameters=None,\n",
       "                                                            verbosity=None))]),\n",
       "                   n_iter=1, n_jobs=2,\n",
       "                   param_distributions={'clf__min_child_weight': [1, 5, 10]},\n",
       "                   random_state=1001,\n",
       "                   scoring=make_scorer(balanced_accuracy_score))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_search.fit(x_train[:100], y_train[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37900874635568516"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RandomizedSearchCV' object has no attribute 'best_estimator_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-f44a8c5ec901>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrandom_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'RandomizedSearchCV' object has no attribute 'best_estimator_'"
     ]
    }
   ],
   "source": [
    "random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.92E+00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>real</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30578</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       real  pred\n",
       "30578     1     3"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real = y_test\n",
    "predicted = estimator.predict(x_test)\n",
    "err = RMSE(predicted, real)\n",
    "print(\"{:.2E}\".format(err))\n",
    "to_show = pd.DataFrame()\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)\n",
    "to_show[\"real\"] = real\n",
    "to_show[\"pred\"] = predicted\n",
    "to_show[to_show[\"pred\"]==3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = 3\n",
    "param_comb = 1\n",
    "\n",
    "params = {\n",
    "    \n",
    "}\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 1001)\n",
    "\n",
    "\n",
    "xgb = XGBClassifier(learning_rate=0.02, n_estimators=1000, objective='binary:logistic',\n",
    "                    silent=True, nthread=6, tree_method='gpu_hist', eval_metric='auc')\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('count', CountVectorizer()),\n",
    "    ('tfid', TruncatedSVD()),\n",
    "    ('clf', XGBClassifier())\n",
    "])\n",
    "\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=params, n_iter=param_comb, cv=skf.split(x_train,y_train), n_jobs=4, verbose=3, random_state=1001 )\n",
    "\n",
    "best_params_reg = {\n",
    "    'count__max_features': 5000,\n",
    "    'count__min_df': 5,\n",
    "    'desc__n_components': 100,\n",
    "    'reg__hidden_layer_sizes': (50, 20),\n",
    "    'reg__max_iter': 50,\n",
    "    'reg__solver': 'adam'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
