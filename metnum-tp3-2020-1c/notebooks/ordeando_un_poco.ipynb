{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ordenando un toque:\n",
    "    - Lo que buscamos es encontrar algún (o algunos) modelos que nos permitan aproximar alguna de las columnas del dataset (si, alguna).\n",
    "    - Si o si tenemos que hacerlo co nla columna \"precio\", pero además tenemos que elgir otra (está en el enunciado).\n",
    "    \n",
    "    - Separemos los tantos:\n",
    "        - Feature Engeniere es algo que vamos a hacer POR FUERA de todo lo que es la ejecución, es decir, cuando nosotros hagamos fit + predict + loquesea, esta nueva columna no tiene idea de que es nueva, asi que esto no nos importa tanto (para lo que es la ejecucion pura y dura)\n",
    "       \n",
    "        - Segmentación + K-fold + errores, es algo que nos interesa DENTRO de la ejecución.\n",
    "        - Ejecutar 1 vez y tomar metricas, no estaría bueno, por lo que ya sabemos (overfitting), entonces no nos queda otra más que para cada segmento, realizar el KFold, callcular las métricas en cada Fold, y guardar el promedio de esas métricas (nos queda un array de metricas promedio en cada segmento).\n",
    "        - ¿Donde empieza el prolema? En que para cada Fold, los valores de los factores de la ecuación de la recta (esos que obtenemos cuando hacemos fit) van a cambiar siempre, porque para cada \"cacho\" de dataset, estas cambian.\n",
    "        - ¿Nos importa realmente? Obviamente googlie esto porque estaba medio perdido, y la respuesta es que no (a priori). Lo primero que a nosotros nos interesa saber, es si nuestro modelo \"esta bueno\", es decir, si el error total es bajo (comparando distintas métricas y demas). Esto no nos da las variables \"finales\", una vez que definimos que algún modelo funciona bien, recién ahí ejecutamos la regresión con TODOS los datos, y no quedamos con los factores resultantes (si usamos segmentación, seria un conjunto de factores para cada segmento, y para predecír deberíamos saber determinar a que segmento pertenece)\n",
    "        \n",
    "        \n",
    "Esto lo saque de acá:\n",
    "https://stats.stackexchange.com/questions/52274/how-to-choose-a-predictive-model-after-k-fold-cross-validation\n",
    "https://stats.stackexchange.com/questions/2306/feature-selection-for-final-model-when-performing-cross-validation-in-machine?rq=1\n",
    "\n",
    "Por si estoy entendiendo cualquier cosa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/.pyenv/versions/3.6.5/envs/metnum-tp3/lib/python3.6/site-packages/pandas/compat/__init__.py:117: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import metnum\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error as RMSE, mean_squared_log_error as RMSLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv('../data/train.csv')\n",
    "df = df_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Segment:\n",
    "    def __init__(self, name, linear_regressor, features):\n",
    "        self.name = name\n",
    "        self.linear_regressor = linear_regressor\n",
    "        self.features = features\n",
    "        \n",
    "    def fit(self, A, reales):\n",
    "        self.linear_regressor.fit(A, reales)\n",
    "\n",
    "    def predict(self, A):\n",
    "        return self.linear_regressor.predict(A)\n",
    "    \n",
    "    def execute(self, A, reales, metrics, k=5):\n",
    "\n",
    "        self.errors = np.zeros_like(metrics)\n",
    "\n",
    "        kf = KFold(n_splits=k)\n",
    "        for train_index, test_index in kf.split(A):\n",
    "            # Divido en datos de entrenamiento y testeo\n",
    "            A_train, A_test = A[train_index], A[test_index]\n",
    "            reales_train, reales_test = reales[train_index], reales[test_index]\n",
    "            # Fiteo con los de entrenamiento\n",
    "            self.fit(A_train, reales_train)\n",
    "\n",
    "            # Predigo con los de testeo\n",
    "            aproximados = self.predict(A_test)\n",
    "            i = 0\n",
    "            # Calculo y guardo las metricas pasadas por parametro\n",
    "            for metric in metrics:\n",
    "                self.errors[i] += metric(reales_test, aproximados)\n",
    "                i += 1\n",
    "        \n",
    "        self.errors /= k\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regresionPorSegmento(df, segment_column, features, metrics, predict_column='precio'):\n",
    "    segments = np.array([])\n",
    "    \n",
    "    for name in df[segment_column].unique():\n",
    "        # Leo los datos correspondientes al segmeto\n",
    "        df_segment = df[df[segment_column] == name] # Aquellos datos que no contengan la columna, no son tomados en cuenta\n",
    "        \n",
    "        A = df_segment[features].values\n",
    "        precios_reales = df_segment[predict_column].values\n",
    "\n",
    "        # Creo el segmento\n",
    "        segment = Segment(name, metnum.LinearRegression(), features)\n",
    "        #print(f'Segemento: {name} \\n')\n",
    "        # Fit y predict\n",
    "        segment.execute(A, precios_reales, metrics)\n",
    "        \n",
    "        # Guardo el segmento\n",
    "        segments = np.append(segments, segment)\n",
    "\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_model(df, segment, features, metrics):\n",
    "    # Limpia los valores con NAN que se vayan a utilizar\n",
    "    df = df.dropna(subset=(features + [segment]))\n",
    "    \n",
    "    return regresionPorSegmento(df, segment, features, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo fruta\n",
    "df = df_original.copy()\n",
    "segment = 'provincia'\n",
    "features = ['metrostotales', \"metroscubiertos\"]   #'metrostotales', 'metroscubiertos', \"habitaciones\", \"banos\", \"antiguedad\"]\n",
    "\n",
    "metrics = [RMSE, RMSLE]\n",
    "\n",
    "segments = exec_model(df, segment, features, metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4156749071464.4873 0.3071691409779902]\n",
      "[1355194492588.362 0.2932669986485194]\n",
      "[1830346961682.852 0.3667594151433021]\n",
      "[740824638139.3896 0.1949426722241246]\n",
      "[1429756211704.571 0.2684862729582663]\n",
      "[388832510605.67365 0.11303979967999667]\n",
      "[408027099872.0533 0.20656126463355434]\n",
      "[2507226433761.599 0.5654948689918251]\n",
      "[932832375466.7946 0.25033169218691]\n",
      "[458740053142.37335 0.14034028903283677]\n",
      "[551829348110.3738 0.23983246108862893]\n",
      "[3091724327733.6313 0.45568317097932176]\n",
      "[1151826759557.8696 0.31166457496731514]\n",
      "[961830726823.1814 0.25869121846451754]\n",
      "[467217023201.6852 0.10813658750774782]\n",
      "[660078633755.4427 0.28600566646616815]\n",
      "[452110401394.4484 0.20387552327436023]\n",
      "[884162547358.2389 0.5432835474034555]\n",
      "[508304407194.47833 0.17915311217726956]\n",
      "[424213926038.9456 0.20798367519430414]\n",
      "[242345793981.44858 0.2610792431345274]\n",
      "[332634478184.8405 0.22302118536357432]\n",
      "[155052789398.07208 0.11925796813690075]\n",
      "[583749072110.8542 0.245949477304237]\n",
      "[780044579972.6852 0.23832602714666504]\n",
      "[231270452101.97314 0.16018304858041998]\n",
      "[336606961952.4432 0.19069104034281284]\n",
      "[443351544062.5057 0.20323242762864452]\n",
      "[766557752019.512 0.16366059950284736]\n",
      "[225651187825.7163 0.11081024868229172]\n",
      "[1142013029722.118 0.4389132307816525]\n",
      "[481342839800.26575 0.24913077967494993]\n"
     ]
    }
   ],
   "source": [
    "for s in segments:\n",
    "    print(s.errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
